{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "def deepfool_attack(model, image, num_classes=10, max_iter=50, epsilon=0.01):\n",
        "    image = tf.convert_to_tensor(image)\n",
        "    image = tf.expand_dims(image, axis=0)\n",
        "    \n",
        "    # Convert the model's output to logits\n",
        "    def model_logits(x):\n",
        "        return model(x, training=False)\n",
        "    \n",
        "    # Define the Jacobian calculation\n",
        "    def jacobian_fn(x):\n",
        "        return tf.gradients(model_logits(x), x)[0]\n",
        "\n",
        "    # Obtain the model's predictions and the corresponding label\n",
        "    f_image = model_logits(image)\n",
        "    I = tf.argsort(tf.reshape(f_image, shape=(num_classes,)), direction='DESCENDING')\n",
        "    I = I[0:num_classes]\n",
        "    label = I[0]\n",
        "    \n",
        "    w = tf.zeros_like(image)\n",
        "    r_tot = tf.zeros_like(image)\n",
        "    \n",
        "    k_i = label\n",
        "    for _ in range(max_iter):\n",
        "        image_variable = tf.Variable(image, dtype=tf.float32)\n",
        "        with tf.GradientTape() as tape:\n",
        "            tape.watch(image_variable)\n",
        "            f_i = tf.reshape(model_logits(image_variable), shape=(num_classes,))\n",
        "            loss = tf.reduce_sum(tf.square(f_i - f_image[label]))\n",
        "            \n",
        "        grad_f_i = tape.gradient(loss, image_variable)\n",
        "        grad_f_i = tf.reshape(grad_f_i, shape=(-1,))\n",
        "        grad_f_i = tf.reshape(grad_f_i, shape=(num_classes, -1))\n",
        "        \n",
        "        num_classes_mask = np.ones(num_classes)\n",
        "        num_classes_mask[k_i] = 0\n",
        "        \n",
        "        # Calculate the perturbation\n",
        "        delta_w = tf.linalg.pinv(grad_f_i) * num_classes_mask[:, np.newaxis]\n",
        "        delta_w_norm = tf.norm(delta_w)\n",
        "        \n",
        "        if delta_w_norm == 0:\n",
        "            break\n",
        "        \n",
        "        r_i = (delta_w_norm + 1e-4) * delta_w / delta_w_norm\n",
        "        r_tot = tf.add(r_tot, r_i)\n",
        "        image = tf.clip_by_value(image + epsilon * r_tot / tf.norm(r_tot), clip_value_min=-1.0, clip_value_max=1.0)\n",
        "        \n",
        "        f_image = model_logits(image)\n",
        "        k_i = tf.argmax(tf.reshape(f_image, shape=(num_classes,)), axis=0)\n",
        "        \n",
        "    perturbation = epsilon * r_tot / tf.norm(r_tot)\n",
        "    adversarial_image = tf.clip_by_value(image + perturbation, clip_value_min=-1.0, clip_value_max=1.0)\n",
        "    \n",
        "    return adversarial_image.numpy()[0]"
      ],
      "metadata": {
        "id": "XSluRxBLG2EX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this implementation, the model parameter represents your TensorFlow model, image is the input image, num_classes is the number of classes in your model's output, max_iter is the maximum number of iterations, and epsilon controls the magnitude of the perturbation.\n",
        "\n",
        "To use this code, you need to provide your own TensorFlow model and an input image. The deepfool_attack function will return an adversarial image that is crafted using the DeepFool attack.\n",
        "\n",
        "Please note that this implementation assumes that your model takes a single input image at a time. If your model expects a batch of images, you may need to make some modifications to accommodate that. Also, be aware of the ethical considerations and legal implications when using adversarial attacks.\n",
        "\n",
        "The image shape used in the provided DeepFool attack implementation is expected to be a 4-dimensional tensor with the shape (batch_size, height, width, channels).\n",
        "\n",
        "In the code snippet, the input image is converted to a TensorFlow tensor using tf.convert_to_tensor(image), and then expanded along the batch dimension using tf.expand_dims(image, axis=0) to create a batch of size 1. Therefore, the expected shape of the input image is (1, height, width, channels).\n",
        "\n",
        "Here's an example of how you can use the DeepFool attack implementation with an input image:\n",
        "\n",
        "\n",
        "The shape of f_image in the provided DeepFool attack implementation would depend on the output shape of your model. In the code snippet, f_image is obtained by passing the input image to the model_logits function, which is assumed to return the logits (raw model output) of the model.\n",
        "\n",
        "Since the shape of f_image is derived from the model's output, it will match the output shape of your specific model. In general, the shape of f_image would be (batch_size, num_classes).\n",
        "\n",
        "For example, if your model is a classification model with 10 classes and expects input images of size (224, 224, 3), and you are using a batch size of 1, then the shape of f_image would be (1, 10).\n",
        "\n",
        "Please ensure that your model and the model_logits function are set up correctly to provide the desired output shape.\n",
        "\n",
        "In the DeepFool attack code provided, w and r_tot are variables used to accumulate the perturbation and track the total perturbation applied to the input image during each iteration of the attack.\n",
        "\n",
        "w: This variable represents the accumulated perturbation that is being added to the input image at each iteration. It is initialized as a tensor of zeros with the same shape as the input image. w is updated by adding the perturbation calculated in each iteration, r_i, to itself.\n",
        "\n",
        "r_tot: This variable keeps track of the total perturbation applied to the input image across all iterations of the attack. It is also initialized as a tensor of zeros with the same shape as the input image. r_tot is updated by adding the perturbation of the current iteration, r_i, to itself.\n",
        "\n",
        "By accumulating the perturbations in w and r_tot over iterations, the DeepFool attack gradually modifies the input image to cause misclassification by pushing it closer to the decision boundary of the target class. The final adversarial image is obtained by adding the accumulated perturbation, r_tot, to the original input image.\n",
        "\n",
        "Both w and r_tot are tensors with the same shape as the input image tensor and are updated in each iteration of the attack loop."
      ],
      "metadata": {
        "id": "tZ6uqSHOHCNu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this code snippet, model refers to the TensorFlow model that you want to perform the DeepFool attack on, image is the input image, num_classes is the number of classes in your model's output, max_iter is the maximum number of iterations, and epsilon controls the magnitude of the perturbation.\n",
        "\n",
        "To use this code, you need to provide your own TensorFlow model and an input image. The deepfool_attack function will return an adversarial image that is crafted using the DeepFool attack.\n",
        "\n",
        "Please note that the implementation provided here is a basic version of DeepFool and may require further customization depending on your specific use case. Additionally, it is important to keep in mind the ethical considerations and legal implications of adversarial attacks."
      ],
      "metadata": {
        "id": "4atXHhiTG3F-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "DeepFool is an adversarial attack method designed to fool machine learning models, particularly deep neural networks. It is an iterative attack algorithm that perturbs input samples with minimal modifications to make them misclassified by the target model.\n",
        "\n",
        "Here's a high-level overview of the DeepFool attack algorithm:\n",
        "\n",
        "Input: A pre-trained target model, a clean input sample to be perturbed, and a maximum number of iterations allowed.\n",
        "Output: Perturbed input sample that is misclassified by the target model.\n",
        "Initialization: Start with the clean input sample.\n",
        "Iteration:\n",
        "Compute the gradient of the target model's output with respect to the input sample.\n",
        "Select the class with the minimum gradient magnitude as the initial adversarial class.\n",
        "Calculate the perturbation required to change the classification to the initial adversarial class using linearization.\n",
        "Update the input sample by adding the perturbation.\n",
        "Repeat the above steps until the perturbed sample is misclassified or the maximum number of iterations is reached.\n",
        "Return: The perturbed sample that is misclassified by the target model.\n",
        "Please note that implementing the DeepFool attack algorithm requires knowledge of the specific deep learning framework you are using, such as TensorFlow or PyTorch, and familiarity with the underlying model's architecture and gradients.\n",
        "\n",
        "Here's an example using TensorFlow to perform the DeepFool attack:"
      ],
      "metadata": {
        "id": "NE4ICP4foePM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the DeepFool attack algorithm, selecting the class with the minimum gradient magnitude as the initial adversarial class is a crucial step to guide the perturbation process towards misclassification.\n",
        "\n",
        "The rationale behind this step is that the class with the minimum gradient magnitude is the most easily \"confusable\" class for the current input sample. By perturbing the input towards this class, the hope is to reach a decision boundary where the target model misclassifies the perturbed sample.\n",
        "\n",
        "The intuition behind selecting the minimum gradient magnitude is based on the assumption that the decision boundary of a well-trained model is smooth and linear in the vicinity of the input sample. In this local linear approximation, the gradient of the model's output represents the direction of steepest ascent or descent towards the decision boundaries.\n",
        "\n",
        "By selecting the class with the minimum gradient magnitude, DeepFool aims to find the smallest perturbation required to cross the decision boundary and misclassify the input sample. The perturbation is calculated based on linearization and is applied iteratively to navigate the input towards the desired adversarial class.\n",
        "\n",
        "In summary, selecting the class with the minimum gradient magnitude as the initial adversarial class helps guide the DeepFool attack towards finding the smallest perturbation that leads to misclassification. It leverages the local linearity assumption to iteratively modify the input sample and fool the target model.\n",
        "\n",
        "## It is important to select the class with the minimum gradient output with respect to the input image because deepfool is an untargeted attack hence selecting this class means that it will be easier to push accross the decision boundy of the model wrt this class"
      ],
      "metadata": {
        "id": "95DK4Rxool64"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.datasets import mnist\n",
        "import matplotlib.pyplot as plt\n",
        "#!pip install -Uqq ipdb\n",
        "import ipdb"
      ],
      "metadata": {
        "id": "VezSKlHno_JT"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pathh = 'MNISTClassifier'\n",
        "\n",
        "# for parent, dirs, files in os.walk(pathh, topdown=False):\n",
        "#   for file in files:\n",
        "#     file_path = os.path.join(parent, file)\n",
        "#     os.remove(file_path)\n",
        "#   for dir in dirs:\n",
        "#     dir_path = os.path.join(parent, dir)\n",
        "#     os.rmdir(dir_path)\n",
        "  \n",
        "#   os.rmdir('/content/MNISTClassifier')"
      ],
      "metadata": {
        "id": "C_T8cxFOzfmY"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%pdb on"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cXFITXClunUV",
        "outputId": "25d85340-fff5-421d-c517-f4e2e873fd53"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Automatic pdb calling has been turned ON\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(images, labels), (test_images, test_labels) = mnist.load_data() \n",
        "images = images.reshape((60000, 28, 28)).astype(\"float32\") / 255\n",
        "images = np.expand_dims(images, axis=3)\n",
        "test_images = test_images.reshape((10000, 28, 28)).astype(\"float32\") / 255\n",
        "test_images = np.expand_dims(test_images, axis=3)\n",
        "x_train, x_test = images[10000:], images[:10000]\n",
        "y_train, y_test = labels[10000:], labels[:10000]"
      ],
      "metadata": {
        "id": "diCfhcOaA1gN"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_test[11].shape\n",
        "digit = x_test[65]\n",
        "fig = plt.figure\n",
        "plt.imshow(digit, cmap='gray')\n",
        "print(y_test[16])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "niWUJxprA7IT",
        "outputId": "4d6c9cb4-2f30-46ea-9e9f-1261eed6ee8e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "few_twos = []\n",
        "count = 0\n",
        "for index, label in enumerate(y_test):\n",
        "  if count > 4:\n",
        "    break\n",
        "  if label == 5:\n",
        "    few_twos.append((index, label))\n",
        "    count += 1\n",
        "\n",
        "print(few_twos)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n23Q_JwaA-Wc",
        "outputId": "001c773f-ceb0-414a-e6e1-e4435756a28d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(0, 5), (11, 5), (35, 5), (47, 5), (65, 5)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MNISTClassifier(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "        super(MNISTClassifier, self).__init__()\n",
        "        \n",
        "        # Define the layers\n",
        "        #for feature extration\n",
        "        self.conv1 = tf.keras.layers.Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1))\n",
        "        self.max_pool1 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))\n",
        "        self.conv2 = tf.keras.layers.Conv2D(64, kernel_size=(3, 3), activation='relu')\n",
        "        self.max_pool2 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))\n",
        "        self.flatten = tf.keras.layers.Flatten()\n",
        "        self.dropout1 = tf.keras.layers.Dropout(0.25)\n",
        "        self.dense1 = tf.keras.layers.Dense(128, activation='relu')\n",
        "        self.dropout2 = tf.keras.layers.Dropout(0.5)\n",
        "        self.dense2 = tf.keras.layers.Dense(10)\n",
        "        self.layers_list = [self.conv1, self.max_pool1, self.conv2, self.max_pool2,\n",
        "                           self.flatten, self.dropout1, self.dense1, self.dropout2, self.dense2]\n",
        "    @tf.function\n",
        "    def call(self, *args, **kwargs):\n",
        "        # Define the forward pass\n",
        "        # output is the model logits\n",
        "        activation_list = []\n",
        "        out = args[0]\n",
        "        for layer in self.layers_list:                  \n",
        "           out = layer(out)\n",
        "           activation_list.append(out)\n",
        "\n",
        "        # if kwargs['training']:\n",
        "        #   #notice that training is a kw argument checked when fit is called\n",
        "        #   #so when model is training, all I need is the output logits to call the loss function upon\n",
        "        #   return out\n",
        "        # else:          \n",
        "          # prob = tf.nn.softmax(out)\n",
        "        return out"
      ],
      "metadata": {
        "id": "7NDxRnObBAFM"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SaveFinalTrainingLogitsProp(keras.callbacks.Callback):\n",
        "  def on_train_end(self, logs):\n",
        "    self.out = model.predict(x_train)\n",
        "    self.prob = tf.nn.softmax(self.out)\n",
        "    print(self.out.shape, self.prob.shape)"
      ],
      "metadata": {
        "id": "3J0KsMyIIG1N"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = MNISTClassifier()\n",
        "model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              optimizer=tf.keras.optimizers.Adam(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(x_train, y_train, epochs=10, validation_data=(x_test, y_test))\n",
        "\n",
        "model.save('MNISTClassifier')\n",
        "# model = keras.models.load_model(\"MNISTClassifier.keras\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e-5wM_r0IKuz",
        "outputId": "27f5af85-50f3-4a19-d24a-afd02907ffaf"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1563/1563 [==============================] - 36s 23ms/step - loss: 0.2375 - accuracy: 0.9265 - val_loss: 0.0664 - val_accuracy: 0.9794\n",
            "Epoch 2/10\n",
            "1563/1563 [==============================] - 35s 23ms/step - loss: 0.0916 - accuracy: 0.9727 - val_loss: 0.0506 - val_accuracy: 0.9863\n",
            "Epoch 3/10\n",
            "1563/1563 [==============================] - 36s 23ms/step - loss: 0.0709 - accuracy: 0.9786 - val_loss: 0.0415 - val_accuracy: 0.9879\n",
            "Epoch 4/10\n",
            "1563/1563 [==============================] - 35s 22ms/step - loss: 0.0585 - accuracy: 0.9824 - val_loss: 0.0401 - val_accuracy: 0.9882\n",
            "Epoch 5/10\n",
            "1563/1563 [==============================] - 35s 22ms/step - loss: 0.0499 - accuracy: 0.9847 - val_loss: 0.0377 - val_accuracy: 0.9896\n",
            "Epoch 6/10\n",
            "1563/1563 [==============================] - 35s 22ms/step - loss: 0.0459 - accuracy: 0.9863 - val_loss: 0.0406 - val_accuracy: 0.9880\n",
            "Epoch 7/10\n",
            "1563/1563 [==============================] - 35s 22ms/step - loss: 0.0422 - accuracy: 0.9869 - val_loss: 0.0376 - val_accuracy: 0.9891\n",
            "Epoch 8/10\n",
            "1563/1563 [==============================] - 35s 23ms/step - loss: 0.0381 - accuracy: 0.9879 - val_loss: 0.0373 - val_accuracy: 0.9903\n",
            "Epoch 9/10\n",
            "1563/1563 [==============================] - 34s 22ms/step - loss: 0.0344 - accuracy: 0.9889 - val_loss: 0.0324 - val_accuracy: 0.9908\n",
            "Epoch 10/10\n",
            "1563/1563 [==============================] - 35s 22ms/step - loss: 0.0328 - accuracy: 0.9903 - val_loss: 0.0349 - val_accuracy: 0.9900\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _update_step_xla while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# select a few twos from the test dataset and reshape\n",
        "# twos are at [(5, 2), (16, 2), (25, 2), (28, 2), (76, 2)]\n",
        "\n",
        "twos_tuple = [(0, 5), (11, 5), (35, 5), (47, 5), (65, 5)]\n",
        "reshaped_sample_twos = []\n",
        "for tup in twos_tuple:\n",
        "  a_two = x_test[tup[0]]\n",
        "  a_two = np.reshape(a_two, (-1, 28, 28, 1))\n",
        "  reshaped_sample_twos.append(a_two)\n",
        "reshaped_sample_twos = np.array(reshaped_sample_twos)\n",
        "# a_five = np.reshape(x_test[47], (-1, 28, 28, 1))\n",
        "# print(a_five.shape)"
      ],
      "metadata": {
        "id": "otIrjnrdIO7h"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(reshaped_sample_twos.shape) #the network expects a rank 4 tensor ie. batch, width, hieght, channel"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jBXt9tAqIRf7",
        "outputId": "291b9533-3a22-483e-ed5b-85d8d3d7ec6c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(5, 1, 28, 28, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# location of 2 in x_test # number 2 are found in these location: [(5, 2), (16, 2), (25, 2), (28, 2), (76, 2)]\n",
        "model = tf.keras.models.load_model('MNISTClassifier')\n",
        "\n",
        "prediction = []\n",
        "for sample in reshaped_sample_twos:\n",
        "  sample_prediction = model.predict(sample)\n",
        "  prediction.append(sample_prediction)\n",
        "# print(np.argmax(prediction))\n",
        "print(np.argmax(prediction[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j7ZK0UrIIUMe",
        "outputId": "34cbfa59-2a0d-4f2b-cc0b-843e1c199b5a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 61ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tf.one_hot(y_test[11], 10)) #creates a 0n-hot encoded output label to enable us calculate the distance"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vQf6m6wDIXvG",
        "outputId": "a06ebc96-d599-4ccb-a484-d7c365a53212"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([0. 0. 0. 0. 0. 1. 0. 0. 0. 0.], shape=(10,), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reshaped_sample_twos[0].shape\n",
        "#squeze to drop first dim\n",
        "squeze_two = np.expand_dims(np.squeeze(reshaped_sample_twos[3]), axis=2)\n",
        "squeze_two.shape\n",
        "x = squeze_two\n",
        "x = np.expand_dims(x, axis=0)\n",
        "x = tf.convert_to_tensor(x)\n",
        "y = y_test[5]\n",
        "y = tf.convert_to_tensor(y)\n",
        "\n",
        "print(y)\n",
        "print(x.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eddhEH-IIaRR",
        "outputId": "e1f3ab44-d163-4f3b-aafe-b225b3e914a7"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(2, shape=(), dtype=uint8)\n",
            "(1, 28, 28, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# def deepfool_attack(model, image, num_classes=10, max_iter=50, epsilon=0.01):\n",
        "#   image = tf.convert_to_tensor(image)\n",
        "  \n",
        "#   # return image.shape\n",
        "\n",
        "#   #get output logit of the image\n",
        "#   def model_logits(x):\n",
        "#     return model(x, training=False)\n",
        "\n",
        "#   # def the jecobian calculation\n",
        "#   def jacobian_fn(x):\n",
        "#     return tf.gradients(model_logits(x), x)[0]\n",
        "\n",
        "#   #get models predictions and corresponding label\n",
        "\n",
        "#   f_image = model_logits(image)\n",
        "\n",
        "#   # reshaped_f = tf.reshape(f_image, shape=(num_classes,))\n",
        "#   I = tf.argsort(tf.squeeze(f_image, axis=0), direction='DESCENDING')\n",
        "#   I = I[0:num_classes]\n",
        "#   label = I[0]\n",
        "\n",
        "#   w = tf.zeros_like(image) \n",
        "#   #tracks accumulated perturbation at each iteration\n",
        "#   r_tot = tf.zeros_like(image) \n",
        "#   #keep track of total perturbation to the input image accross all iterations\n",
        "\n",
        "#   k_i = label\n",
        "\n",
        "#   for _ in range(max_iter):\n",
        "#     image_variable = tf.Variable(image, dtype=tf.float32)\n",
        "#     with tf.GradientTape() as tape:\n",
        "#       tape.watch(image_variable)\n",
        "#       f_i = tf.squeeze(model_logits(image_variable), axis=0)\n",
        "#       # print(\"f_image\", f_image)\n",
        "#       # print(\"f_image[label]\", f_image[0][label])\n",
        "#       loss = tf.reduce_sum(tf.square(f_i - f_image[0][label]))\n",
        "    \n",
        "#     grad_f_i = tape.gradient(loss, image_variable)\n",
        "#     grad_f_i = tf.reshape(grad_f_i, shape=(-1,))\n",
        "#     grad_f_i = tf.reshape(grad_f_i, shape=(num_classes, -1))\n",
        "\n",
        "#     num_classes_mask = np.ones(num_classes)\n",
        "#     num_classes_mask[k_i] = 0 #set tge corresponding class label to zero\n",
        "#     num_classes_mask[:, np.newaxis] # shape =(10, 1)\n",
        "    \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#   return num_classes_mask[:, np.newaxis].shape, tf.reshape(tf.squeeze(grad_f_i, axis=0), shape=(num_classes, -1))\n",
        "\n",
        "    "
      ],
      "metadata": {
        "id": "J-VyAYlyj8-j"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def deepfool_attack(model, image, num_classes=10, max_iter=100, epsilon=1e-6):\n",
        "  image = tf.convert_to_tensor(image)\n",
        "\n",
        "  @tf.function\n",
        "  def compute_gradients(inputs):\n",
        "      with tf.GradientTape() as tape:\n",
        "          tape.watch(inputs)\n",
        "          logits = model(inputs, training=False)\n",
        "          prediction = tf.argmax(logits, axis=1)\n",
        "          loss = tf.reduce_sum(tf.square(logits - tf.one_hot(prediction, num_classes)))\n",
        "      gradients = tape.gradient(loss, inputs)\n",
        "      return gradients\n",
        "\n",
        "  image_shape = image.shape[1:]\n",
        "  # print(\"image_shape\", image_shape)\n",
        "  image = tf.cast(image, tf.float32)\n",
        "  # print(\"faa\", image.shape)\n",
        "  perturbation = tf.zeros_like(image)\n",
        "  count = 0\n",
        "  for idx in range(max_iter):\n",
        "      image = tf.cast(image, tf.float32)\n",
        "      image_perturbed = tf.cast(image + perturbation, tf.float32)\n",
        "\n",
        "      # Compute the gradients of the loss w.r.t. the input\n",
        "      gradients = compute_gradients(image_perturbed)\n",
        "\n",
        "      # Compute the label with the current model predictions\n",
        "      current_label = tf.argmax(model(image_perturbed), axis=1).numpy()[0]\n",
        "      # print(\"current label\", current_label)\n",
        "\n",
        "      # Initialize variables for minimal perturbation search\n",
        "      min_norm = np.inf\n",
        "      min_perturbation = tf.zeros_like(image)\n",
        "      gradients = tf.reshape(gradients, shape=(image_shape))\n",
        "\n",
        "      for i in range(num_classes):\n",
        "          if i == current_label:\n",
        "              continue\n",
        "\n",
        "          # Compute the gradient direction\n",
        "          w = gradients.numpy()[0] - gradients.numpy()[i]\n",
        "          # print(\"w\", w.shape)\n",
        "\n",
        "          # Compute the minimal perturbation\n",
        "          norm = np.linalg.norm(w.flatten())\n",
        "\n",
        "          # print(\"norm\", norm)\n",
        "\n",
        "          if norm < min_norm and norm != 0:\n",
        "              min_norm = norm\n",
        "              min_perturbation = w / (norm)  # Add epsilon to avoid division by zero\n",
        "              # print(\"min pert\", min_perturbation)\n",
        "              # print(\"min pert\", min_perturbation)\n",
        "      # Update the perturbation\n",
        "      perturbation = tf.cast(perturbation + min_perturbation, tf.float32)\n",
        "      count = idx\n",
        "\n",
        "  adversarial_image = tf.clip_by_value(image + perturbation, 0.0, 1.0)\n",
        "  return adversarial_image.numpy(), count\n",
        "      \n"
      ],
      "metadata": {
        "id": "23aHEQ6OKffF"
      },
      "execution_count": 193,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# preprocessed_image = preprocess_image(image)\n",
        "\n",
        "# Perform DeepFool attack\n",
        "adv_img, count = deepfool_attack(model, x)\n",
        "print(count)\n",
        "\n",
        "digit = tf.squeeze(adv_img, axis=0)\n",
        "orig_digit = tf.squeeze(x, axis=0)\n",
        "# print(s_adv_img.shape)\n",
        "\n",
        "plt.imshow(orig_digit, cmap='gray')\n",
        "\n",
        "print(np.argmax(model.predict(adv_img)))\n",
        "# Postprocess the perturbed image and original image if needed\n",
        "# postprocessed_perturbed_image = postprocess_image(perturbed_image)\n",
        "# postprocessed_orig_image = postprocess_image(orig_image)\n",
        "\n",
        "# Evaluate the perturbed image with the model\n",
        "# predictions = model.predict(np.array(perturbed_image))\n",
        "# predicted_class = np.argmax(predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 482
        },
        "id": "1MXYFbETsmvF",
        "outputId": "12040b28-ea02-430f-8a88-fd5949e8d37e"
      },
      "execution_count": 195,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "99\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(digit, cmap='gray')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "Py8sijmAVIFH",
        "outputId": "6b4b389f-c747-429a-d5f9-9098dfdaeeba"
      },
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f4fd4829b40>"
            ]
          },
          "metadata": {},
          "execution_count": 148
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}